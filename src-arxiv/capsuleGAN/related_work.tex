\section{Related Work}
\label{sec:related_work}

GANs were originally implemented as feedforward multi-layer perceptrons, which did not perform well on generating complex images like those in the CIFAR-10 dataset~\cite{bib:cifar}. They suffered from mode collapse and were highly unstable to train~\cite{bib:dcgan, bib:igan}. In an attempt to solve these problems, Radford et al.~\cite{bib:dcgan} presented a set of guidelines to design GANs as a class of CNNs, giving rise to DCGANs, which have since been a dominant approach to GAN network architecture design. Im et al.~\cite{bib:gran} later proposed the use of Recurrent Neural Networks instead of CNNs as generators for GANs, creating a new class of GANs referred to as Generative Recurrent Adversarial Networks or GRANs. On a related note, Odena et al.~\cite{bib:acgan} proposed an architectural change to GANs in the form of a discriminator that also acts as a classifier for class-conditional image generation. This approach for designing discriminators has been a popular choice for conditional GANs~\cite{bib:cgan} recently. Our work is similar in line with~\cite{bib:acgan} in the sense that we propose an architectural change to discriminators. We propose to transition from designing GAN discriminators as CNNs to formulating them as CapsNets, creating a new class of GANs called CapsuleGANs. This idea can be extended to encoder-based GANs like BiGAN~\cite{bib:bigan} where the encoder can be modeled as a CapsNet also.